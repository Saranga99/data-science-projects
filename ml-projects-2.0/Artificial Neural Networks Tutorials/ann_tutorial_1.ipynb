{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple example with two inputs and one output and logic AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp, array, random, dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "inputs = array([[0,0],[0,1],[1,0],[1,1]])\n",
    "outputs = array([[0,1,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16595599],\n",
       "       [ 0.44064899]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 2 * random.random((2,1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single neuron\n",
    "def neuron(inputs,weights):\n",
    "    output = 1 /  (1 + exp(-(dot(inputs,weights))))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "for iteration in range(500000):\n",
    "    output = 1 / (1 + exp(-(dot(inputs,weights))))\n",
    "    weights += dot(inputs.T, (outputs - output) * output * (1 - output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.998998]\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "x = array([1,0])\n",
    "print(neuron(x,weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0.,0.],[0.,1.],[1.,0.],[1.,1.]]\n",
    "y = [0,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver=\"lbfgs\", alpha=1e-5, hidden_layer_sizes=(5,2), random_state=1)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[(2, 5), (5, 2), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[2.,2.],[-1.,-2.]]))\n",
    "print([coef.shape for coef in clf.coefs_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple Keras multiple layer perceptron for the Breast Cancer Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP \n",
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(10,activation=\"relu\",input_shape=[X_train.shape[1]]))\n",
    "#middle layer\n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "#output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431\n",
      "Trainable params: 431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 40ms/step - loss: 304.9879 - mse: 304.9879 - val_loss: 277.7376 - val_mse: 277.7376\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 224.1872 - mse: 224.1872 - val_loss: 227.3209 - val_mse: 227.3209\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 123.4153 - mse: 123.4153 - val_loss: 208.6044 - val_mse: 208.6044\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 127.0920 - mse: 127.0920 - val_loss: 164.6770 - val_mse: 164.6770\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 97.0928 - mse: 97.0928 - val_loss: 145.4313 - val_mse: 145.4313\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 83.0052 - mse: 83.0052 - val_loss: 111.3906 - val_mse: 111.3906\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 63.1056 - mse: 63.1056 - val_loss: 98.4010 - val_mse: 98.4010\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 55.3452 - mse: 55.3452 - val_loss: 84.1339 - val_mse: 84.1339\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 46.6020 - mse: 46.6020 - val_loss: 75.2697 - val_mse: 75.2697\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 41.5570 - mse: 41.5570 - val_loss: 67.8724 - val_mse: 67.8724\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 36.1534 - mse: 36.1534 - val_loss: 60.2586 - val_mse: 60.2586\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 33.6186 - mse: 33.6186 - val_loss: 53.7241 - val_mse: 53.7241\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 28.9618 - mse: 28.9618 - val_loss: 50.7008 - val_mse: 50.7008\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 25.1168 - mse: 25.1168 - val_loss: 43.6276 - val_mse: 43.6276\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 24.2526 - mse: 24.2526 - val_loss: 39.4037 - val_mse: 39.4037\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 21.7831 - mse: 21.7831 - val_loss: 36.6642 - val_mse: 36.6642\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 18.6383 - mse: 18.6383 - val_loss: 32.4102 - val_mse: 32.4102\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 16.3670 - mse: 16.3670 - val_loss: 30.9194 - val_mse: 30.9194\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 15.0406 - mse: 15.0406 - val_loss: 26.9733 - val_mse: 26.9733\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 13.6890 - mse: 13.6890 - val_loss: 25.7261 - val_mse: 25.7261\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 12.6266 - mse: 12.6266 - val_loss: 22.8377 - val_mse: 22.8377\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 11.3124 - mse: 11.3124 - val_loss: 21.2590 - val_mse: 21.2590\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 10.3931 - mse: 10.3931 - val_loss: 20.0455 - val_mse: 20.0455\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 9.5894 - mse: 9.5894 - val_loss: 18.8330 - val_mse: 18.8330\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.8672 - mse: 8.8672 - val_loss: 17.5550 - val_mse: 17.5550\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 8.3869 - mse: 8.3869 - val_loss: 17.0182 - val_mse: 17.0182\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.2028 - mse: 8.2028 - val_loss: 15.8880 - val_mse: 15.8880\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 7.9546 - mse: 7.9546 - val_loss: 15.7262 - val_mse: 15.7262\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.3490 - mse: 7.3490 - val_loss: 14.4685 - val_mse: 14.4685\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 7.6341 - mse: 7.6341 - val_loss: 14.4239 - val_mse: 14.4239\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 7.0129 - mse: 7.0129 - val_loss: 13.4165 - val_mse: 13.4165\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 6.3190 - mse: 6.3190 - val_loss: 13.1910 - val_mse: 13.1910\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.7944 - mse: 5.7944 - val_loss: 12.7970 - val_mse: 12.7970\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 5.4763 - mse: 5.4763 - val_loss: 11.9911 - val_mse: 11.9911\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.1917 - mse: 5.1917 - val_loss: 12.0352 - val_mse: 12.0352\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.9728 - mse: 4.9728 - val_loss: 11.1616 - val_mse: 11.1616\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.9661 - mse: 4.9661 - val_loss: 11.2187 - val_mse: 11.2187\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.9949 - mse: 4.9949 - val_loss: 10.5154 - val_mse: 10.5154\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.8179 - mse: 4.8179 - val_loss: 10.6904 - val_mse: 10.6904\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.2610 - mse: 4.2610 - val_loss: 10.0439 - val_mse: 10.0439\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.0679 - mse: 4.0679 - val_loss: 9.6879 - val_mse: 9.6879\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3.9708 - mse: 3.9708 - val_loss: 9.6624 - val_mse: 9.6624\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.1402 - mse: 4.1402 - val_loss: 9.1728 - val_mse: 9.1728\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.1814 - mse: 4.1814 - val_loss: 9.6283 - val_mse: 9.6283\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.7461 - mse: 3.7461 - val_loss: 9.0879 - val_mse: 9.0879\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.4950 - mse: 3.4950 - val_loss: 8.7243 - val_mse: 8.7243\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.5725 - mse: 3.5725 - val_loss: 8.4326 - val_mse: 8.4326\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 3.2917 - mse: 3.2917 - val_loss: 8.4534 - val_mse: 8.4534\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 3.0168 - mse: 3.0168 - val_loss: 8.2071 - val_mse: 8.2071\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2.9210 - mse: 2.9210 - val_loss: 8.5014 - val_mse: 8.5014\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.8873 - mse: 2.8873 - val_loss: 7.6069 - val_mse: 7.6069\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2.9020 - mse: 2.9020 - val_loss: 8.0452 - val_mse: 8.0452\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.9040 - mse: 2.9040 - val_loss: 7.3023 - val_mse: 7.3023\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.8232 - mse: 2.8232 - val_loss: 8.2598 - val_mse: 8.2598\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.9207 - mse: 2.9207 - val_loss: 7.0640 - val_mse: 7.0640\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.5768 - mse: 2.5768 - val_loss: 7.9440 - val_mse: 7.9440\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.5720 - mse: 2.5720 - val_loss: 6.9794 - val_mse: 6.9794\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3484 - mse: 2.3484 - val_loss: 7.0464 - val_mse: 7.0464\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3533 - mse: 2.3533 - val_loss: 6.6190 - val_mse: 6.6190\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3708 - mse: 2.3708 - val_loss: 6.8236 - val_mse: 6.8236\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.1722 - mse: 2.1722 - val_loss: 6.5039 - val_mse: 6.5039\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.1752 - mse: 2.1752 - val_loss: 6.9783 - val_mse: 6.9783\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.1058 - mse: 2.1058 - val_loss: 6.3701 - val_mse: 6.3701\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.0221 - mse: 2.0221 - val_loss: 6.6397 - val_mse: 6.6397\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.9709 - mse: 1.9709 - val_loss: 6.1605 - val_mse: 6.1605\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.9441 - mse: 1.9441 - val_loss: 6.8216 - val_mse: 6.8216\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.9245 - mse: 1.9245 - val_loss: 5.9693 - val_mse: 5.9693\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8655 - mse: 1.8655 - val_loss: 6.2946 - val_mse: 6.2946\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.8360 - mse: 1.8360 - val_loss: 6.0048 - val_mse: 6.0048\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.8768 - mse: 1.8768 - val_loss: 5.6007 - val_mse: 5.6007\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.9404 - mse: 1.9404 - val_loss: 6.6911 - val_mse: 6.6911\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.8673 - mse: 1.8673 - val_loss: 5.6847 - val_mse: 5.6847\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.2217 - mse: 2.2217 - val_loss: 6.4225 - val_mse: 6.4225\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.8918 - mse: 1.8918 - val_loss: 5.7874 - val_mse: 5.7874\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.7293 - mse: 1.7293 - val_loss: 5.4015 - val_mse: 5.4015\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.6373 - mse: 1.6373 - val_loss: 6.2743 - val_mse: 6.2743\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.6088 - mse: 1.6088 - val_loss: 5.3000 - val_mse: 5.3000\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.5706 - mse: 1.5706 - val_loss: 6.2636 - val_mse: 6.2636\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4904 - mse: 1.4904 - val_loss: 5.1778 - val_mse: 5.1778\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.6332 - mse: 1.6332 - val_loss: 5.7955 - val_mse: 5.7955\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4431 - mse: 1.4431 - val_loss: 5.2630 - val_mse: 5.2630\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4040 - mse: 1.4040 - val_loss: 5.4697 - val_mse: 5.4697\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3859 - mse: 1.3859 - val_loss: 5.0360 - val_mse: 5.0360\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.5467 - mse: 1.5467 - val_loss: 6.0540 - val_mse: 6.0540\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5190 - mse: 1.5190 - val_loss: 5.0867 - val_mse: 5.0867\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2950 - mse: 1.2950 - val_loss: 5.4736 - val_mse: 5.4736\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3117 - mse: 1.3117 - val_loss: 5.1955 - val_mse: 5.1955\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3659 - mse: 1.3659 - val_loss: 4.8450 - val_mse: 4.8450\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3460 - mse: 1.3460 - val_loss: 5.0270 - val_mse: 5.0270\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3244 - mse: 1.3244 - val_loss: 5.8942 - val_mse: 5.8942\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6022 - mse: 1.6022 - val_loss: 4.8235 - val_mse: 4.8235\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3816 - mse: 1.3816 - val_loss: 5.1423 - val_mse: 5.1423\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2357 - mse: 1.2357 - val_loss: 5.4860 - val_mse: 5.4860\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2525 - mse: 1.2525 - val_loss: 4.8142 - val_mse: 4.8142\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1606 - mse: 1.1606 - val_loss: 5.3805 - val_mse: 5.3805\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1120 - mse: 1.1120 - val_loss: 4.8778 - val_mse: 4.8778\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0787 - mse: 1.0787 - val_loss: 5.3405 - val_mse: 5.3405\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0876 - mse: 1.0876 - val_loss: 4.9900 - val_mse: 4.9900\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0532 - mse: 1.0532 - val_loss: 5.1126 - val_mse: 5.1126\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0595 - mse: 1.0595 - val_loss: 5.1223 - val_mse: 5.1223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x287ee5371f0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"mean_squared_error\",metrics=[\"mse\"])\n",
    "model.fit(X_train,y_train,batch_size=50,validation_split=0.2,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8214 - mse: 0.8214\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.8213662505149841\n",
      "accuracy : 0.8213662505149841\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss : {results[0]}\")\n",
    "print(f\"accuracy : {results[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26b1b087b6115fdce9f4a178c333b5c26160129b7c43447de3043909f8978fb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
